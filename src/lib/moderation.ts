// Syst√®me de mod√©ration automatique avec Azure Content Moderator - Version optimis√©e pour √©viter stack depth
import { supabase } from './supabase';

// Configuration Azure Content Moderator
const AZURE_CONFIG = {
  endpoint: import.meta.env.VITE_AZURE_CONTENT_MODERATOR_ENDPOINT,
  subscriptionKey: import.meta.env.VITE_AZURE_CONTENT_MODERATOR_KEY,
  region: import.meta.env.VITE_AZURE_REGION || 'francecentral',
};

// Types pour la mod√©ration
export interface ModerationResult {
  isApproved: boolean;
  confidence: number;
  categories: {
    adult: number;
    violence: number;
    hate: number;
    selfHarm: number;
  };
  flags: string[];
  requiresHumanReview: boolean;
  reason?: string;
}

export interface ModerationRecord {
  id: string;
  content_id: string;
  content_type: 'image' | 'video' | 'text' | 'url';
  status: 'pending' | 'approved' | 'rejected' | 'reviewing';
  auto_result: ModerationResult;
  human_review?: {
    reviewer_id: string;
    decision: 'approve' | 'reject';
    reason?: string;
    reviewed_at: string;
  };
  created_at: string;
  updated_at: string;
}

// Seuils optimis√©s pour plateforme adulte l√©gale
const MODERATION_THRESHOLDS = {
  // Seuils pour approbation automatique (scores faibles = contenu s√ªr)
  AUTO_APPROVE: {
    adult: 0.95,       // 95% - Tr√®s permissif sur le contenu adulte (c'est le th√®me de la plateforme)
    violence: 0.1,     // 10% - Tr√®s strict sur la violence
    hate: 0.05,        // 5% - Extr√™mement strict sur les discours haineux
    selfHarm: 0.05,    // 5% - Extr√™mement strict sur l'auto-mutilation
  },
  // Seuils pour rejet automatique (scores √©lev√©s = contenu probl√©matique)
  AUTO_REJECT: {
    adult: 0.99,       // 99% - Seul le contenu extr√™me est rejet√© automatiquement
    violence: 0.2,     // 20% - Rejet automatique d√®s 20% de violence d√©tect√©e
    hate: 0.2,         // 20% - Rejet automatique d√®s 20% de discours haineux
    selfHarm: 0.2,     // 20% - Rejet automatique d√®s 20% d'auto-mutilation
  },
  // Entre les deux = r√©vision humaine requise
};

// V√©rification de la configuration Azure
export const checkAzureConfiguration = (): { configured: boolean; message: string } => {
  const hasEndpoint = !!AZURE_CONFIG.endpoint && AZURE_CONFIG.endpoint !== 'your_azure_endpoint';
  const hasKey = !!AZURE_CONFIG.subscriptionKey && AZURE_CONFIG.subscriptionKey !== 'your_azure_subscription_key';
  
  console.log('üîß Azure Configuration Check:', {
    hasEndpoint,
    hasKey,
    endpoint: AZURE_CONFIG.endpoint ? `${AZURE_CONFIG.endpoint.substring(0, 30)}...` : 'missing',
    region: AZURE_CONFIG.region
  });
  
  if (!hasEndpoint || !hasKey) {
    return {
      configured: false,
      message: 'Azure Content Moderator non configur√©. Variables d\'environnement manquantes.'
    };
  }
  
  return {
    configured: true,
    message: 'Azure Content Moderator configur√© et pr√™t.'
  };
};

// Validation de la configuration Azure
const validateAzureConfig = (): boolean => {
  const config = checkAzureConfiguration();
  
  if (!config.configured) {
    console.warn('‚ö†Ô∏è Azure Content Moderator not configured. Using fallback moderation.');
    console.warn('üí° Pour configurer Azure:');
    console.warn('   1. Cr√©ez un service Azure Content Moderator');
    console.warn('   2. Ajoutez les variables d\'environnement:');
    console.warn('      VITE_AZURE_CONTENT_MODERATOR_ENDPOINT=https://your-resource.cognitiveservices.azure.com/');
    console.warn('      VITE_AZURE_CONTENT_MODERATOR_KEY=your_subscription_key');
    console.warn('      VITE_AZURE_REGION=francecentral');
    return false;
  }
  
  return true;
};

// Mod√©ration d'image avec Azure Content Moderator
export const moderateImage = async (imageUrl: string): Promise<ModerationResult> => {
  try {
    if (!validateAzureConfig()) {
      console.log('üîÑ Using fallback moderation for image');
      return fallbackImageModeration(imageUrl);
    }

    console.log('üîç Moderating image with Azure:', imageUrl.substring(0, 50) + '...');

    // Utiliser l'edge function pour la mod√©ration Azure avec timeout
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 15000); // 15 second timeout

    try {
      const { data, error } = await supabase.functions.invoke('moderate-content', {
        body: {
          type: 'image',
          url: imageUrl,
          config: {
            endpoint: AZURE_CONFIG.endpoint,
            subscriptionKey: AZURE_CONFIG.subscriptionKey,
            region: AZURE_CONFIG.region
          }
        }
      });

      clearTimeout(timeoutId);

      if (error) {
        console.warn('‚ö†Ô∏è Azure moderation failed, using fallback:', error);
        return fallbackImageModeration(imageUrl);
      }

      if (data && data.success) {
        console.log('‚úÖ Azure moderation successful:', data.result);
        return data.result;
      } else {
        console.warn('‚ö†Ô∏è Azure returned invalid response, using fallback');
        return fallbackImageModeration(imageUrl);
      }
    } catch (invokeError: any) {
      clearTimeout(timeoutId);
      
      if (invokeError.name === 'AbortError') {
        console.warn('‚ö†Ô∏è Azure moderation timeout, using fallback');
      } else {
        console.warn('‚ö†Ô∏è Azure moderation error, using fallback:', invokeError);
      }
      
      return fallbackImageModeration(imageUrl);
    }

  } catch (error) {
    console.error('‚ùå Error moderating image:', error);
    return fallbackImageModeration(imageUrl);
  }
};

// Mod√©ration de texte avec Azure Content Moderator
export const moderateText = async (text: string): Promise<ModerationResult> => {
  try {
    if (!validateAzureConfig()) {
      console.log('üîÑ Using fallback moderation for text');
      return fallbackTextModeration(text);
    }

    console.log('üîç Moderating text with Azure:', text.substring(0, 100) + '...');

    // Utiliser l'edge function pour la mod√©ration Azure avec timeout
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 15000); // 15 second timeout

    try {
      const { data, error } = await supabase.functions.invoke('moderate-content', {
        body: {
          type: 'text',
          content: text,
          config: {
            endpoint: AZURE_CONFIG.endpoint,
            subscriptionKey: AZURE_CONFIG.subscriptionKey,
            region: AZURE_CONFIG.region
          }
        }
      });

      clearTimeout(timeoutId);

      if (error) {
        console.warn('‚ö†Ô∏è Azure text moderation failed, using fallback:', error);
        return fallbackTextModeration(text);
      }

      if (data && data.success) {
        console.log('‚úÖ Azure text moderation successful:', data.result);
        return data.result;
      } else {
        console.warn('‚ö†Ô∏è Azure returned invalid response, using fallback');
        return fallbackTextModeration(text);
      }
    } catch (invokeError: any) {
      clearTimeout(timeoutId);
      
      if (invokeError.name === 'AbortError') {
        console.warn('‚ö†Ô∏è Azure text moderation timeout, using fallback');
      } else {
        console.warn('‚ö†Ô∏è Azure text moderation error, using fallback:', invokeError);
      }
      
      return fallbackTextModeration(text);
    }

  } catch (error) {
    console.error('‚ùå Error moderating text:', error);
    return fallbackTextModeration(text);
  }
};

// √âvaluation des scores de mod√©ration avec seuils optimis√©s
const evaluateModerationScores = (categories: ModerationResult['categories'], flags: string[]): ModerationResult => {
  const maxScore = Math.max(...Object.values(categories));
  
  // Logique sp√©cialis√©e pour plateforme adulte
  
  // V√©rifier si le contenu doit √™tre rejet√© automatiquement (violence, haine, auto-mutilation)
  const shouldReject = 
    categories.violence > MODERATION_THRESHOLDS.AUTO_REJECT.violence ||
    categories.hate > MODERATION_THRESHOLDS.AUTO_REJECT.hate ||
    categories.selfHarm > MODERATION_THRESHOLDS.AUTO_REJECT.selfHarm ||
    categories.adult > MODERATION_THRESHOLDS.AUTO_REJECT.adult; // Seul le contenu adulte extr√™me

  // V√©rifier si le contenu peut √™tre approuv√© automatiquement
  const canAutoApprove = 
    categories.violence <= MODERATION_THRESHOLDS.AUTO_APPROVE.violence &&
    categories.hate <= MODERATION_THRESHOLDS.AUTO_APPROVE.hate &&
    categories.selfHarm <= MODERATION_THRESHOLDS.AUTO_APPROVE.selfHarm;
    // Note: pas de restriction sur le contenu adulte pour l'approbation automatique

  let isApproved: boolean;
  let requiresHumanReview: boolean;
  let reason: string | undefined;

  if (shouldReject) {
    isApproved = false;
    requiresHumanReview = false;
    
    // Messages sp√©cifiques selon le type de contenu probl√©matique
    if (categories.violence > MODERATION_THRESHOLDS.AUTO_REJECT.violence) {
      reason = `Contenu rejet√©: Violence d√©tect√©e (${(categories.violence * 100).toFixed(1)}%)`;
    } else if (categories.hate > MODERATION_THRESHOLDS.AUTO_REJECT.hate) {
      reason = `Contenu rejet√©: Discours haineux d√©tect√© (${(categories.hate * 100).toFixed(1)}%)`;
    } else if (categories.selfHarm > MODERATION_THRESHOLDS.AUTO_REJECT.selfHarm) {
      reason = `Contenu rejet√©: Auto-mutilation d√©tect√©e (${(categories.selfHarm * 100).toFixed(1)}%)`;
    } else {
      reason = `Contenu rejet√©: Contenu extr√™me d√©tect√© (${flags.join(', ')})`;
    }
  } else if (canAutoApprove) {
    isApproved = true;
    requiresHumanReview = false;
    
    if (categories.adult > 0.5) {
      reason = `Contenu adulte approuv√© automatiquement (${(categories.adult * 100).toFixed(1)}% adulte, conforme √† la plateforme)`;
    } else {
      reason = `Contenu approuv√© automatiquement (scores de s√©curit√© acceptables)`;
    }
  } else {
    isApproved = false;
    requiresHumanReview = true;
    
    // Messages sp√©cifiques pour la r√©vision humaine
    if (categories.violence > MODERATION_THRESHOLDS.AUTO_APPROVE.violence) {
      reason = `R√©vision humaine requise: Violence d√©tect√©e (${(categories.violence * 100).toFixed(1)}%)`;
    } else if (categories.hate > MODERATION_THRESHOLDS.AUTO_APPROVE.hate) {
      reason = `R√©vision humaine requise: Discours potentiellement haineux (${(categories.hate * 100).toFixed(1)}%)`;
    } else if (categories.selfHarm > MODERATION_THRESHOLDS.AUTO_APPROVE.selfHarm) {
      reason = `R√©vision humaine requise: Auto-mutilation potentielle (${(categories.selfHarm * 100).toFixed(1)}%)`;
    } else {
      reason = `R√©vision humaine requise: Contenu n√©cessitant une √©valuation manuelle`;
    }
  }

  return {
    isApproved,
    confidence: 1 - maxScore, // Plus le score est bas, plus on est confiant
    categories,
    flags,
    requiresHumanReview,
    reason,
  };
};

// Mod√©ration de fallback (sans Azure) - OPTIMIS√âE POUR CONTENU ADULTE
const fallbackImageModeration = (imageUrl: string): ModerationResult => {
  console.log('üîÑ Using enhanced fallback image moderation for adult platform');
  
  // Mod√©ration basique bas√©e sur l'URL et le nom de fichier
  const url = imageUrl.toLowerCase();
  const flags: string[] = [];
  
  // Seuils optimis√©s pour plateforme adulte
  const categories = { 
    adult: 0.7,      // Assume du contenu adulte par d√©faut (c'est normal sur cette plateforme)
    violence: 0.05,  // Tr√®s faible par d√©faut
    hate: 0.05,      // Tr√®s faible par d√©faut
    selfHarm: 0.05   // Tr√®s faible par d√©faut
  };

  // Mots-cl√©s probl√©matiques (violence, haine, etc.)
  const violenceKeywords = ['blood', 'weapon', 'gun', 'knife', 'violence', 'kill', 'murder'];
  const hateKeywords = ['nazi', 'racist', 'hate', 'terrorist', 'supremacist'];
  const selfHarmKeywords = ['suicide', 'selfharm', 'cutting', 'harm'];
  
  const foundViolence = violenceKeywords.some(keyword => url.includes(keyword));
  const foundHate = hateKeywords.some(keyword => url.includes(keyword));
  const foundSelfHarm = selfHarmKeywords.some(keyword => url.includes(keyword));
  
  if (foundViolence) {
    categories.violence = 0.8;
    flags.push('violence_keywords');
  }
  
  if (foundHate) {
    categories.hate = 0.9;
    flags.push('hate_keywords');
  }
  
  if (foundSelfHarm) {
    categories.selfHarm = 0.9;
    flags.push('selfharm_keywords');
  }
  
  // Pour le contenu adulte normal, on l'accepte
  flags.push('adult_content_platform');

  const result = evaluateModerationScores(categories, flags);
  console.log('üìä Fallback moderation result (adult platform optimized):', result);
  
  return result;
};

const fallbackTextModeration = (text: string): ModerationResult => {
  console.log('üîÑ Using enhanced fallback text moderation for adult platform');
  
  const lowerText = text.toLowerCase();
  const flags: string[] = [];
  
  // Seuils optimis√©s pour plateforme adulte
  const categories = { 
    adult: 0.6,      // Contenu adulte attendu et accept√©
    violence: 0.05,  // Tr√®s strict sur la violence
    hate: 0.05,      // Tr√®s strict sur la haine
    selfHarm: 0.05   // Tr√®s strict sur l'auto-mutilation
  };

  // Mots-cl√©s de violence (tr√®s strict)
  const violenceKeywords = ['kill', 'murder', 'violence', 'weapon', 'gun', 'knife', 'blood', 'torture', 'abuse'];
  const hateKeywords = ['hate', 'racist', 'nazi', 'terrorist', 'supremacist', 'genocide', 'discrimination'];
  const selfHarmKeywords = ['suicide', 'selfharm', 'cutting', 'harm yourself', 'kill yourself'];

  violenceKeywords.forEach(keyword => {
    if (lowerText.includes(keyword)) {
      categories.violence = Math.max(categories.violence, 0.9);
      flags.push('violence_language');
    }
  });

  hateKeywords.forEach(keyword => {
    if (lowerText.includes(keyword)) {
      categories.hate = Math.max(categories.hate, 0.95);
      flags.push('hate_speech');
    }
  });

  selfHarmKeywords.forEach(keyword => {
    if (lowerText.includes(keyword)) {
      categories.selfHarm = Math.max(categories.selfHarm, 0.95);
      flags.push('selfharm_content');
    }
  });

  // Le contenu adulte est normal sur cette plateforme
  flags.push('adult_platform_content');

  const result = evaluateModerationScores(categories, flags);
  console.log('üìä Fallback text moderation result (adult platform optimized):', result);
  
  return result;
};

// Mod√©ration automatique d'un m√©dia sp√©cifique
export const moderateMediaFile = async (mediaId: string): Promise<ModerationRecord> => {
  console.log('üõ°Ô∏è Starting moderation for media:', mediaId);

  try {
    // R√©cup√©rer les informations du m√©dia
    const { data: mediaData, error: mediaError } = await supabase
      .from('mediafile')
      .select('*')
      .eq('id', mediaId)
      .single();

    if (mediaError || !mediaData) {
      throw new Error('Media not found');
    }

    console.log('üìÅ Media data:', mediaData);

    // V√©rifier si ce m√©dia a d√©j√† √©t√© mod√©r√©
    const { data: existingModeration } = await supabase
      .from('content_moderation')
      .select('*')
      .eq('content_id', mediaId)
      .single();

    if (existingModeration) {
      console.log('‚ö†Ô∏è Media already moderated:', existingModeration);
      return existingModeration as ModerationRecord;
    }

    // Mod√©rer le m√©dia selon son type
    let moderationResult: ModerationResult;
    
    if (mediaData.mime_type.startsWith('image/')) {
      moderationResult = await moderateImage(mediaData.cloudflare_url);
    } else if (mediaData.mime_type.startsWith('video/')) {
      // Pour les vid√©os, utiliser une mod√©ration basique pour l'instant
      moderationResult = fallbackImageModeration(mediaData.cloudflare_url);
    } else {
      // Pour les autres fichiers, mod√©ration tr√®s permissive
      moderationResult = {
        isApproved: true,
        confidence: 0.9,
        categories: { adult: 0.1, violence: 0.05, hate: 0.05, selfHarm: 0.05 },
        flags: ['document_file'],
        requiresHumanReview: false,
        reason: 'Document file - auto-approved'
      };
    }

    // Cr√©er l'enregistrement de mod√©ration
    const moderationRecord = {
      id: `mod_media_${Date.now()}_${Math.random().toString(36).substring(2)}`,
      content_id: mediaId,
      content_type: mediaData.mime_type.startsWith('image/') ? 'image' as const : 'video' as const,
      status: moderationResult.isApproved ? 'approved' as const : 
              moderationResult.requiresHumanReview ? 'pending' as const : 'rejected' as const,
      auto_result: moderationResult,
      created_at: new Date().toISOString(),
      updated_at: new Date().toISOString(),
    };

    // Sauvegarder dans la base de donn√©es
    const { error: saveError } = await supabase
      .from('content_moderation')
      .insert(moderationRecord);

    if (saveError) {
      console.error('‚ùå Error saving moderation record:', saveError);
      throw saveError;
    }

    console.log('‚úÖ Media moderation completed:', {
      mediaId,
      status: moderationRecord.status,
      confidence: moderationResult.confidence,
      flags: moderationResult.flags,
    });

    return moderationRecord as ModerationRecord;

  } catch (error) {
    console.error('‚ùå Error during media moderation:', error);
    
    // En cas d'erreur, cr√©er un enregistrement qui n√©cessite une r√©vision humaine
    const errorRecord = {
      id: `mod_error_${Date.now()}`,
      content_id: mediaId,
      content_type: 'image' as const,
      status: 'pending' as const,
      auto_result: {
        isApproved: false,
        confidence: 0,
        categories: { adult: 0, violence: 0, hate: 0, selfHarm: 0 },
        flags: ['moderation_error'],
        requiresHumanReview: true,
        reason: `Moderation error: ${error instanceof Error ? error.message : 'Unknown error'}`,
      },
      created_at: new Date().toISOString(),
      updated_at: new Date().toISOString(),
    };

    // Essayer de sauvegarder l'enregistrement d'erreur
    try {
      await supabase
        .from('content_moderation')
        .insert(errorRecord);
    } catch (saveError) {
      console.error('‚ùå Failed to save error record:', saveError);
    }

    return errorRecord as ModerationRecord;
  }
};

// Mod√©ration compl√®te d'un contenu
export const moderateContent = async (contentData: {
  id: string;
  title: string;
  description?: string;
  content_type: 'media' | 'link';
  media_url?: string;
  external_url?: string;
}): Promise<ModerationRecord> => {
  console.log('üõ°Ô∏è Starting content moderation for:', contentData.id);

  try {
    // V√©rifier si ce contenu a d√©j√† √©t√© mod√©r√©
    const { data: existingModeration } = await supabase
      .from('content_moderation')
      .select('*')
      .eq('content_id', contentData.id)
      .single();

    if (existingModeration) {
      console.log('‚ö†Ô∏è Content already moderated:', existingModeration);
      return existingModeration as ModerationRecord;
    }

    // Mod√©rer le titre
    const titleResult = await moderateText(contentData.title);
    
    // Mod√©rer la description si elle existe
    let descriptionResult: ModerationResult | null = null;
    if (contentData.description) {
      descriptionResult = await moderateText(contentData.description);
    }

    // Mod√©rer le contenu m√©dia si c'est une image
    let mediaResult: ModerationResult | null = null;
    if (contentData.content_type === 'media' && contentData.media_url) {
      // V√©rifier si c'est une image (pour la mod√©ration visuelle)
      if (contentData.media_url.includes('image') || 
          contentData.media_url.match(/\.(jpg|jpeg|png|gif|webp)$/i)) {
        mediaResult = await moderateImage(contentData.media_url);
      }
    }

    // Mod√©rer l'URL externe si elle existe
    let urlResult: ModerationResult | null = null;
    if (contentData.content_type === 'link' && contentData.external_url) {
      urlResult = await moderateText(contentData.external_url);
    }

    // Combiner tous les r√©sultats pour une d√©cision finale
    const allResults = [titleResult, descriptionResult, mediaResult, urlResult].filter(Boolean) as ModerationResult[];
    
    const combinedResult = combineResults(allResults);

    // Cr√©er l'enregistrement de mod√©ration
    const moderationRecord = {
      id: `mod_${Date.now()}_${Math.random().toString(36).substring(2)}`,
      content_id: contentData.id,
      content_type: contentData.content_type === 'media' ? 'image' as const : 'url' as const,
      status: combinedResult.isApproved ? 'approved' as const : 
              combinedResult.requiresHumanReview ? 'pending' as const : 'rejected' as const,
      auto_result: combinedResult,
      created_at: new Date().toISOString(),
      updated_at: new Date().toISOString(),
    };

    // Sauvegarder dans la base de donn√©es
    const { error: saveError } = await supabase
      .from('content_moderation')
      .insert(moderationRecord);

    if (saveError) {
      console.error('‚ùå Error saving moderation record:', saveError);
      throw saveError;
    }

    console.log('‚úÖ Content moderation completed:', {
      contentId: contentData.id,
      status: moderationRecord.status,
      confidence: combinedResult.confidence,
      flags: combinedResult.flags,
    });

    return moderationRecord as ModerationRecord;

  } catch (error) {
    console.error('‚ùå Error during content moderation:', error);
    
    // En cas d'erreur, cr√©er un enregistrement qui n√©cessite une r√©vision humaine
    const errorRecord = {
      id: `mod_error_${Date.now()}`,
      content_id: contentData.id,
      content_type: 'image' as const,
      status: 'pending' as const,
      auto_result: {
        isApproved: false,
        confidence: 0,
        categories: { adult: 0, violence: 0, hate: 0, selfHarm: 0 },
        flags: ['moderation_error'],
        requiresHumanReview: true,
        reason: `Moderation error: ${error instanceof Error ? error.message : 'Unknown error'}`,
      },
      created_at: new Date().toISOString(),
      updated_at: new Date().toISOString(),
    };

    try {
      await supabase
        .from('content_moderation')
        .insert(errorRecord);
    } catch (saveError) {
      console.error('‚ùå Failed to save error record:', saveError);
    }

    return errorRecord as ModerationRecord;
  }
};

// Combiner plusieurs r√©sultats de mod√©ration
const combineResults = (results: ModerationResult[]): ModerationResult => {
  if (results.length === 0) {
    return {
      isApproved: false,
      confidence: 0,
      categories: { adult: 0, violence: 0, hate: 0, selfHarm: 0 },
      flags: ['no_results'],
      requiresHumanReview: true,
      reason: 'No moderation results available',
    };
  }

  // Prendre les scores maximum de chaque cat√©gorie
  const combinedCategories = {
    adult: Math.max(...results.map(r => r.categories.adult)),
    violence: Math.max(...results.map(r => r.categories.violence)),
    hate: Math.max(...results.map(r => r.categories.hate)),
    selfHarm: Math.max(...results.map(r => r.categories.selfHarm)),
  };

  // Combiner tous les flags
  const combinedFlags = [...new Set(results.flatMap(r => r.flags))];

  return evaluateModerationScores(combinedCategories, combinedFlags);
};

// Obtenir les statistiques de mod√©ration avec requ√™tes optimis√©es
export const getModerationStats = async (): Promise<{
  total: number;
  approved: number;
  rejected: number;
  pending: number;
  autoApprovalRate: number;
}> => {
  try {
    console.log('üìä Getting moderation stats with optimized queries...');
    
    // Utiliser des requ√™tes COUNT avec select minimal pour √©viter le stack depth error
    const [totalResult, approvedResult, rejectedResult, pendingResult] = await Promise.all([
      // Total count - select only id to minimize query complexity
      supabase
        .from('content_moderation')
        .select('id', { count: 'exact', head: true }),
      
      // Approved count
      supabase
        .from('content_moderation')
        .select('id', { count: 'exact', head: true })
        .eq('status', 'approved'),
      
      // Rejected count
      supabase
        .from('content_moderation')
        .select('id', { count: 'exact', head: true })
        .eq('status', 'rejected'),
      
      // Pending count
      supabase
        .from('content_moderation')
        .select('id', { count: 'exact', head: true })
        .eq('status', 'pending')
    ]);

    // V√©rifier les erreurs
    if (totalResult.error) {
      console.error('‚ùå Error fetching total count:', totalResult.error);
      throw totalResult.error;
    }
    if (approvedResult.error) {
      console.error('‚ùå Error fetching approved count:', approvedResult.error);
      throw approvedResult.error;
    }
    if (rejectedResult.error) {
      console.error('‚ùå Error fetching rejected count:', rejectedResult.error);
      throw rejectedResult.error;
    }
    if (pendingResult.error) {
      console.error('‚ùå Error fetching pending count:', pendingResult.error);
      throw pendingResult.error;
    }

    const stats = {
      total: totalResult.count || 0,
      approved: approvedResult.count || 0,
      rejected: rejectedResult.count || 0,
      pending: pendingResult.count || 0,
      autoApprovalRate: 0,
    };

    // Calculer le taux d'approbation automatique
    stats.autoApprovalRate = stats.total > 0 ? (stats.approved / stats.total) * 100 : 0;

    console.log('‚úÖ Moderation stats calculated successfully:', stats);
    return stats;
    
  } catch (error) {
    console.error('‚ùå Error getting moderation stats:', error);
    
    // En cas d'erreur, retourner des stats par d√©faut
    return {
      total: 0,
      approved: 0,
      rejected: 0,
      pending: 0,
      autoApprovalRate: 0,
    };
  }
};

// R√©vision humaine
export const submitHumanReview = async (
  moderationId: string,
  decision: 'approve' | 'reject',
  reason?: string
): Promise<void> => {
  try {
    const { data: { user } } = await supabase.auth.getUser();
    if (!user) throw new Error('User not authenticated');

    const humanReview = {
      reviewer_id: user.id,
      decision,
      reason,
      reviewed_at: new Date().toISOString(),
    };

    const newStatus = decision === 'approve' ? 'approved' : 'rejected';

    const { error } = await supabase
      .from('content_moderation')
      .update({
        status: newStatus,
        human_review: humanReview,
        updated_at: new Date().toISOString(),
      })
      .eq('id', moderationId);

    if (error) throw error;

    console.log('‚úÖ Human review submitted:', { moderationId, decision, reason });
  } catch (error) {
    console.error('‚ùå Error submitting human review:', error);
    throw error;
  }
};

// Mod√©rer tous les m√©dias existants
export const moderateAllExistingMedia = async (): Promise<{
  processed: number;
  approved: number;
  rejected: number;
  pending: number;
  errors: string[];
}> => {
  console.log('üîÑ Starting bulk moderation of existing media...');
  
  try {
    // R√©cup√©rer tous les m√©dias qui n'ont pas encore √©t√© mod√©r√©s
    const { data: mediaFiles, error: mediaError } = await supabase
      .from('mediafile')
      .select(`
        id,
        filename,
        mime_type,
        cloudflare_url,
        created_at
      `)
      .order('created_at', { ascending: false })
      .limit(50); // Limiter pour √©viter les probl√®mes de performance

    if (mediaError) {
      throw mediaError;
    }

    if (!mediaFiles || mediaFiles.length === 0) {
      return {
        processed: 0,
        approved: 0,
        rejected: 0,
        pending: 0,
        errors: ['No media files found']
      };
    }

    console.log(`üìä Found ${mediaFiles.length} media files to check`);

    // V√©rifier quels m√©dias ont d√©j√† √©t√© mod√©r√©s
    const { data: existingModerations, error: moderationError } = await supabase
      .from('content_moderation')
      .select('content_id')
      .in('content_id', mediaFiles.map(m => m.id));

    if (moderationError) {
      console.warn('Warning: Could not check existing moderations:', moderationError);
    }

    const moderatedIds = new Set(existingModerations?.map(m => m.content_id) || []);
    const unmoderatdMedia = mediaFiles.filter(media => !moderatedIds.has(media.id));

    console.log(`üìã ${unmoderatdMedia.length} media files need moderation`);

    let processed = 0;
    let approved = 0;
    let rejected = 0;
    let pending = 0;
    const errors: string[] = [];

    // Mod√©rer chaque m√©dia
    for (const media of unmoderatdMedia) {
      try {
        console.log(`üîç Moderating media: ${media.filename}`);
        
        const moderationRecord = await moderateMediaFile(media.id);
        processed++;

        switch (moderationRecord.status) {
          case 'approved':
            approved++;
            break;
          case 'rejected':
            rejected++;
            break;
          case 'pending':
            pending++;
            break;
        }

        // Petite pause pour √©viter de surcharger l'API
        await new Promise(resolve => setTimeout(resolve, 100));

      } catch (error: any) {
        console.error(`‚ùå Error moderating media ${media.filename}:`, error);
        errors.push(`${media.filename}: ${error.message}`);
      }
    }

    const result = {
      processed,
      approved,
      rejected,
      pending,
      errors
    };

    console.log('‚úÖ Bulk moderation completed:', result);
    return result;

  } catch (error: any) {
    console.error('‚ùå Error during bulk moderation:', error);
    return {
      processed: 0,
      approved: 0,
      rejected: 0,
      pending: 0,
      errors: [error.message]
    };
  }
};